{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5N_g7ya0y9n"
      },
      "source": [
        "# Endocytosis\n",
        "\n",
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/end1.gif\" height=\"200\">\n",
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/end2.gif\" height=\"200\">\n",
        "\n",
        "TIRF can visualize the formation of clathrin-coated pits, recruitment of adaptor proteins, and vesicle scission from the plasma membrane.\n",
        "\n",
        "Since only the membrane-proximal region is illuminated, once vesicles move away from the membrane (into the cytoplasm), they disappear from the TIRF field, indicating internalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8JDmOrtc0t1"
      },
      "source": [
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/shape_header.svg\" height=\"350\">\n",
        "\n",
        "SHAPE is an open-source framework for processing TIRF-SIM time-lapse data. It enables reconstruction, detection, linking, and analysis of plasma membrane processes such as clathrin-mediated endocytosis and exocytosis. With its modular design and automated workflow, SHAPE enhances tracking accuracy, reduces manual intervention, and supports high-throughput analysis of vesicle transport and productivity.\n",
        "\n",
        "Explore reconstruction, object detection, linking, and analysis in this tutorial to assess your super-resolution data.\n",
        "\n",
        "For more information, visit [GitHub repository link]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbjbIhCGfvjo"
      },
      "source": [
        "**üìãInstructions**\n",
        "\n",
        "1. üõ†Ô∏è Install Dependencies -\n",
        "Automatically install requirements and download test data.\n",
        "1. üóÇÔ∏è Load Input Data - Use the provided test data or upload your own dataset.\n",
        "\n",
        "2. ‚öôÔ∏èSet Parameters -\n",
        "Adjust parameters in the provided setup cell or use defaults.\n",
        "\n",
        "3. üß© Reconstruct TIRF-SIM Images -\n",
        "Combine 9 low-resolution images into a super-resolution reconstruction with preprocessing to reduce noise and artifacts.\n",
        "\n",
        "4. üîç Detect Objects -\n",
        "Use neural networks for object localization and shape extraction, optimized for robust segmentation.\n",
        "\n",
        "5. üîó Linking -\n",
        "Connect detections across frames by optimizing spatial and shape-based matching for globally consistent trajectories.\n",
        "\n",
        "6. üìà Analyze -\n",
        "Analyze complete object trajectories to test hypotheses and derive biological insights.\n",
        "\n",
        "üí° Notes:\n",
        "* If possible, enable GPU in Google Colab by selecting Runtime > Change runtime type, choosing GPU, and clicking Save.\n",
        "\n",
        "* If using large files, you might run out of RAM. Consider using smaller data or upgrading to Colab Pro for more memory and faster GPU access.\n",
        "\n",
        "Start each section below by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\">.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LoahgJqWlNH4"
      },
      "outputs": [],
      "source": [
        "#@title üõ†Ô∏è Install Dependencies\n",
        "\n",
        "%autosave 300\n",
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "def download_and_unzip(url, extract_to, chain_path):\n",
        "    \"\"\"Downloads and unzips a file if not already extracted.\"\"\"\n",
        "    if os.path.exists(extract_to):\n",
        "        print(f\"The directory '{extract_to}' already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "    local_zip_file = url.split(\"/\")[-1]\n",
        "    response = requests.get(url, stream=True, verify=chain_path)\n",
        "    with open(local_zip_file, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "    os.makedirs(extract_to, exist_ok=True)\n",
        "    with zipfile.ZipFile(local_zip_file, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    os.remove(local_zip_file)\n",
        "    print(f\"Downloaded and extracted to '{extract_to}'.\")\n",
        "\n",
        "def install_packages(packages):\n",
        "    \"\"\"Installs the required packages if not already installed.\"\"\"\n",
        "    for package in packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "            print(f\"'{package}' is already installed. Skipping.\")\n",
        "        except ImportError:\n",
        "            print(f\"Installing '{package}'...\")\n",
        "            try:\n",
        "                subprocess.run(\n",
        "                    [\"pip\", \"install\", package],\n",
        "                    check=True,\n",
        "                    stdout=subprocess.PIPE,\n",
        "                    stderr=subprocess.PIPE,\n",
        "                )\n",
        "                print(f\"'{package}' installed successfully.\")\n",
        "            except subprocess.CalledProcessError as e:\n",
        "                print(f\"An error occurred while installing '{package}': {e.stderr.decode().strip()}\")\n",
        "\n",
        "\n",
        "# Download SSL certificate\n",
        "chain_path = '/content/chain-harica-cross.pem'\n",
        "r = requests.get(\n",
        "    'https://pki.cesnet.cz/_media/certs/chain-harica-rsa-ov-crosssigned-root.pem',\n",
        "    timeout=10, stream=True\n",
        ")\n",
        "r.raise_for_status()\n",
        "with open(chain_path, 'wb') as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "# Download test data\n",
        "zip_url = \"https://shape.utia.cas.cz/files/endocytosis/shape2.0_107.zip\"\n",
        "extract_directory = \"/content/shape\"\n",
        "download_and_unzip(zip_url, extract_directory, chain_path)\n",
        "os.chdir(extract_directory)\n",
        "module_path = os.path.abspath(os.path.join('src/'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "required_packages = [\"ortools\", \"czifile\", \"mrcfile\", \"nd2\"]\n",
        "install_packages(required_packages)\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "from scipy import spatial\n",
        "\n",
        "from preprocessing import subtract_background, fade_border, deconvolve_richardson_lucy\n",
        "from parameter_estimation import estimate_phase_modulation, estimate_phase_offset, estimate_integer_shift, optimizer_shift_v2, compute_minimum_distance\n",
        "from reconstruction import separate_components, run_reconstruction\n",
        "from otf import OTF\n",
        "from gpu_reconstruction import Reconstruction, AcquisitionParameters, ReconstructionParameters\n",
        "from unet import UNet\n",
        "from detection import generate_ccp_detections\n",
        "from linking import LinkingGraph, UntanglingGraph, print_solver_status\n",
        "from jupyter_utils import *\n",
        "\n",
        "from ipywidgets import widgets, VBox, Output\n",
        "\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "from IPython.display import Javascript\n",
        "from google.colab import widgets as colab_widgets\n",
        "\n",
        "from google.colab import files\n",
        "import time\n",
        "\n",
        "def animate_50_frames(lr_images):\n",
        "    \"\"\"\n",
        "    Create and return a FuncAnimation for the first 50 frames of lr_images.\n",
        "    \"\"\"\n",
        "    # Take the first 50 frames\n",
        "    sub_movie = lr_images[:50]\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    im = ax.imshow(sub_movie[0], cmap='gray', animated=True)\n",
        "\n",
        "    def update(frame):\n",
        "        im.set_array(sub_movie[frame])\n",
        "        return [im]\n",
        "\n",
        "    ani = animation.FuncAnimation(\n",
        "        fig,\n",
        "        update,\n",
        "        frames=sub_movie.shape[0],\n",
        "        interval=100,\n",
        "        blit=True\n",
        "    )\n",
        "    plt.close(fig)\n",
        "    return HTML(ani.to_jshtml())\n",
        "\n",
        "html_code_wait = \"\"\"\n",
        "    <div id=\"loading-msg\"\">\n",
        "      <br /><br />\n",
        "      <b>\n",
        "        <span style=\"\n",
        "          display: inline-block;\n",
        "          animation: flipPause 2s ease infinite;\n",
        "        \">‚è≥</span>\n",
        "        Please wait...\n",
        "      </b>\n",
        "    </div>\n",
        "\n",
        "    <style>\n",
        "    @keyframes flipPause {\n",
        "      0%   { transform: rotate(0deg); }\n",
        "      40%  { transform: rotate(180deg); }\n",
        "      50%  { transform: rotate(180deg); }\n",
        "      90% { transform: rotate(360deg); }\n",
        "      100% { transform: rotate(360deg); }\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "\n",
        "html_code_clock = \"\"\"\n",
        "    <div id=\"loading-msg\"\">\n",
        "      <br /><br />\n",
        "      <b>\n",
        "        <span style=\"\n",
        "          display: inline-block;\n",
        "          animation: flipPause 2s ease infinite;\n",
        "        \">‚è≥</span>\n",
        "        Loading the animation, please wait...\n",
        "      </b>\n",
        "    </div>\n",
        "\n",
        "    <style>\n",
        "    @keyframes flipPause {\n",
        "      0%   { transform: rotate(0deg); }\n",
        "      40%  { transform: rotate(180deg); }\n",
        "      50%  { transform: rotate(180deg); }\n",
        "      90% { transform: rotate(360deg); }\n",
        "      100% { transform: rotate(360deg); }\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\"\n",
        "\n",
        "html_code_reconstruction = \"\"\"\n",
        "<div id=\"loading-msg\">\n",
        "  <br /><br />\n",
        "  <b>\n",
        "    <span style=\"\n",
        "      display: inline-block;\n",
        "      animation: flipPause 2s ease infinite;\n",
        "    \">‚è≥</span>\n",
        "    Preparing data for reconstruction, please wait...\n",
        "  </b>\n",
        "</div>\n",
        "\n",
        "<style>\n",
        "@keyframes flipPause {\n",
        "  0%   { transform: rotate(0deg); }\n",
        "  40%  { transform: rotate(180deg); }\n",
        "  50%  { transform: rotate(180deg); }\n",
        "  90%  { transform: rotate(360deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "html_code_detection = \"\"\"\n",
        "<div id=\"loading-msg\">\n",
        "  <br /><br />\n",
        "  <b>\n",
        "    <span style=\"\n",
        "      display: inline-block;\n",
        "      animation: flipPause 2s ease infinite;\n",
        "    \">‚è≥</span>\n",
        "    Preparing data for detection, please wait...\n",
        "  </b>\n",
        "</div>\n",
        "\n",
        "<style>\n",
        "@keyframes flipPause {\n",
        "  0%   { transform: rotate(0deg); }\n",
        "  40%  { transform: rotate(180deg); }\n",
        "  50%  { transform: rotate(180deg); }\n",
        "  90%  { transform: rotate(360deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "html_code_linking = \"\"\"\n",
        "<div id=\"loading-msg\">\n",
        "  <br /><br />\n",
        "  <b>\n",
        "    <span style=\"\n",
        "      display: inline-block;\n",
        "      animation: flipPause 2s ease infinite;\n",
        "    \">‚è≥</span>\n",
        "    Preparing data for linking, please wait...\n",
        "  </b>\n",
        "</div>\n",
        "\n",
        "<style>\n",
        "@keyframes flipPause {\n",
        "  0%   { transform: rotate(0deg); }\n",
        "  40%  { transform: rotate(180deg); }\n",
        "  50%  { transform: rotate(180deg); }\n",
        "  90%  { transform: rotate(360deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "html_code_linking2 = \"\"\"\n",
        "<div id=\"loading-msg\">\n",
        "  <br /><br />\n",
        "  <b>\n",
        "    <span style=\"\n",
        "      display: inline-block;\n",
        "      animation: flipPause 2s ease infinite;\n",
        "    \">‚è≥</span>\n",
        "    Linking, please wait...\n",
        "  </b>\n",
        "</div>\n",
        "\n",
        "<style>\n",
        "@keyframes flipPause {\n",
        "  0%   { transform: rotate(0deg); }\n",
        "  40%  { transform: rotate(180deg); }\n",
        "  50%  { transform: rotate(180deg); }\n",
        "  90%  { transform: rotate(360deg); }\n",
        "  100% { transform: rotate(360deg); }\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ You are all set!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRv4xRw0XJ2i"
      },
      "source": [
        "# Endocytosis: single-channel movie"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8a-RObmD6wl"
      },
      "source": [
        "Continue  by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "izCIdcrcc_YV"
      },
      "outputs": [],
      "source": [
        "#@title üóÇÔ∏è Load Input Data\n",
        "import os, zipfile, json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from ipyfilechooser import FileChooser\n",
        "from google.colab import drive\n",
        "\n",
        "# Global memory variables\n",
        "filename = None          # .dv file path\n",
        "mask_filename = None     # mask .tif file path\n",
        "parameters = {}          # loaded JSON dict\n",
        "param_file_used = None   # JSON used path\n",
        "\n",
        "DEFAULT_PARAM_FILE = \"data/Oxford/20240703/default_parameters.json\"\n",
        "\n",
        "# 1Ô∏è‚É£ Data Mode Radio Buttons\n",
        "data_mode = widgets.RadioButtons(\n",
        "    options=[('Use Test Data','test'),('Use Own Data (Drive)','drive'),('Precomputed Data (Zip)','zip')],\n",
        "    value='test', description='Data Mode:'\n",
        ")\n",
        "\n",
        "# 2Ô∏è‚É£ Test Data Dropdown\n",
        "test_data_dropdown = widgets.Dropdown(\n",
        "    options=[\n",
        "        'data/Oxford/20240703/SHSY5Y_RUSHLAMP_CLCSNAP_107_subset.dv'\n",
        "    ],\n",
        "    value='data/Oxford/20240703/SHSY5Y_RUSHLAMP_CLCSNAP_107_subset.dv',\n",
        "    description='Test Data:'\n",
        ")\n",
        "test_box = widgets.VBox([test_data_dropdown])\n",
        "\n",
        "# 3Ô∏è‚É£ File Choosers (hidden initially)\n",
        "drive_chooser_dv = FileChooser('.', title=\"Select .dv file\", show_hidden=False)\n",
        "drive_chooser_dv.filter_pattern = ['*.dv']\n",
        "drive_chooser_dv.layout.display = 'none'\n",
        "\n",
        "drive_chooser_mask = FileChooser('.', title=\"Select mask .tif file\", show_hidden=False)\n",
        "drive_chooser_mask.filter_pattern = ['*.tif']\n",
        "drive_chooser_mask.layout.display = 'none'\n",
        "\n",
        "zip_chooser = FileChooser('.', title=\"Select data .zip file\", show_hidden=False)\n",
        "zip_chooser.filter_pattern = ['*.zip']\n",
        "zip_chooser.layout.display = 'none'\n",
        "\n",
        "# 4Ô∏è‚É£ Layout Containers & Outputs\n",
        "input_container = widgets.VBox()\n",
        "status_out = widgets.Output()\n",
        "final_out = widgets.Output()\n",
        "\n",
        "\n",
        "\n",
        "# 5Ô∏è‚É£ Handle Data Mode Changes\n",
        "def on_mode_change(change):\n",
        "    if change['name']!='value': return\n",
        "    mode = change['new']\n",
        "    status_out.clear_output(); final_out.clear_output()\n",
        "    # hide all\n",
        "    test_box.layout.display='none'; drive_chooser_dv.layout.display='none'\n",
        "    drive_chooser_mask.layout.display='none'; zip_chooser.layout.display='none'\n",
        "    # mount if needed\n",
        "    if mode in ('drive','zip'):\n",
        "        if not os.path.isdir('/content/drive/MyDrive'):\n",
        "            with status_out:\n",
        "                print(\"üîÑ Mounting Google Drive...\")\n",
        "            drive.mount('/content/drive')\n",
        "            with status_out:\n",
        "                print(\"‚úÖ Google Drive mounted.\")\n",
        "        base = '/content/drive/MyDrive'\n",
        "        drive_chooser_dv.reset(base); drive_chooser_mask.reset(base); zip_chooser.reset(base)\n",
        "    # show\n",
        "    if mode=='test':\n",
        "        test_box.layout.display=None; input_container.children=[test_box]\n",
        "    elif mode=='drive':\n",
        "        drive_chooser_dv.layout.display=None; drive_chooser_mask.layout.display=None\n",
        "        input_container.children=[drive_chooser_dv,drive_chooser_mask]\n",
        "    else:\n",
        "        zip_chooser.layout.display=None; input_container.children=[zip_chooser]\n",
        "\n",
        "data_mode.observe(on_mode_change,names='value')\n",
        "input_container.children=[test_box]\n",
        "\n",
        "# 6Ô∏è‚É£ Finalize & Validate\n",
        "def finalize(_):\n",
        "    global filename,mask_filename,parameters,param_file_used\n",
        "    with final_out:\n",
        "        final_out.clear_output(); mode=data_mode.value\n",
        "        # TEST\n",
        "        if mode=='test':\n",
        "            dv=test_data_dropdown.value\n",
        "            if not os.path.isfile(dv): print(f\"‚ö†Ô∏è Test .dv not found: {dv}\"); return\n",
        "            filename=dv; param_file_used=DEFAULT_PARAM_FILE if os.path.isfile(DEFAULT_PARAM_FILE) else None\n",
        "            if param_file_used: parameters=json.load(open(param_file_used))\n",
        "            mask_filename=filename.replace('subset.dv','MASK.tif')\n",
        "            print(\"‚úÖ Loaded Test Data\"); print(f\".dv: {filename}\"); print(f\"Mask: {mask_filename}\"); print(f\"Params: {param_file_used}\"); return\n",
        "        # DRIVE\n",
        "        if mode == 'drive':\n",
        "            try:\n",
        "                dv_base = drive_chooser_dv.selected_path\n",
        "                if dv_base is None:\n",
        "                    raise ValueError(\"No .dv file selected\")\n",
        "                if os.path.isdir(dv_base):\n",
        "                    name = drive_chooser_dv.selected_filename\n",
        "                    dv = os.path.join(dv_base, name) if name else dv_base\n",
        "                else:\n",
        "                    dv = dv_base\n",
        "                if not os.path.isfile(dv):\n",
        "                    print(f\"‚ö†Ô∏è .dv file not found: {dv}\")\n",
        "                    return\n",
        "                filename = dv\n",
        "            except Exception as e:\n",
        "                print(\"‚ö†Ô∏è Please select a valid .dv file and click 'Select'.\")\n",
        "                return\n",
        "\n",
        "            try:\n",
        "                m_base = drive_chooser_mask.selected_path\n",
        "                if m_base is None:\n",
        "                    raise ValueError(\"No mask file selected\")\n",
        "                if os.path.isdir(m_base):\n",
        "                    mname = drive_chooser_mask.selected_filename\n",
        "                    mask = os.path.join(m_base, mname) if mname else m_base\n",
        "                else:\n",
        "                    mask = m_base\n",
        "                if not os.path.isfile(mask):\n",
        "                    print(f\"‚ö†Ô∏è Mask file not found: {mask}\")\n",
        "                    return\n",
        "                mask_filename = mask\n",
        "            except Exception as e:\n",
        "                print(\"‚ö†Ô∏è Please select a valid mask .tif file and click 'Select'.\")\n",
        "                return\n",
        "\n",
        "            param_file_used = DEFAULT_PARAM_FILE if os.path.isfile(DEFAULT_PARAM_FILE) else None\n",
        "            if param_file_used:\n",
        "                parameters = json.load(open(param_file_used))\n",
        "\n",
        "            print(\"‚úÖ Loaded Drive Data\")\n",
        "            print(f\".dv: {filename}\")\n",
        "            print(f\"Mask: {mask_filename}\")\n",
        "            print(f\"Params: {param_file_used}\")\n",
        "            return\n",
        "\n",
        "        # ZIP\n",
        "        if mode == 'zip':\n",
        "            try:\n",
        "                zip_base = zip_chooser.selected_path\n",
        "                if zip_base is None:\n",
        "                    raise ValueError(\"No zip file selected\")\n",
        "                if os.path.isdir(zip_base):\n",
        "                    zname = zip_chooser.selected_filename\n",
        "                    zp = os.path.join(zip_base, zname) if zname else zip_base\n",
        "                else:\n",
        "                    zp = zip_base\n",
        "                if not os.path.isfile(zp):\n",
        "                    print(f\"‚ö†Ô∏è .zip not found: {zp}\")\n",
        "                    return\n",
        "            except Exception as e:\n",
        "                print(\"‚ö†Ô∏è Please select a valid .zip file and click 'Select'.\")\n",
        "                return\n",
        "\n",
        "            with status_out:\n",
        "                status_out.clear_output()\n",
        "                print(f\"‚è≥ Extracting {zp}...\")\n",
        "\n",
        "            extract_dir = 'precomputed_data'\n",
        "            with zipfile.ZipFile(zp, 'r') as zf:\n",
        "                zf.extractall(extract_dir)\n",
        "\n",
        "            pth = os.path.join(extract_dir, 'parameters.json')\n",
        "            if os.path.isfile(pth):\n",
        "                parameters = json.load(open(pth))\n",
        "                param_file_used = pth\n",
        "            else:\n",
        "                param_file_used = None\n",
        "\n",
        "            filename = os.path.join(extract_dir, 'input.dv')\n",
        "            mask_filename = os.path.join(extract_dir, 'mask_file.tif')\n",
        "\n",
        "            print(\"‚úÖ Loaded Precomputed Data\")\n",
        "            print(f\"Params: {param_file_used}\")\n",
        "            print(f\".dv: {filename}\")\n",
        "            print(f\"Mask: {mask_filename}\")\n",
        "\n",
        "\n",
        "\n",
        "# 7Ô∏è‚É£ Display UI\n",
        "def run_ui():\n",
        "    print(\"Select Data Mode below:\"); display(data_mode); display(input_container)\n",
        "    btn=widgets.Button(description=\"Confirm Your Choices\",button_style='success')\n",
        "    btn.on_click(finalize); display(btn,status_out,final_out)\n",
        "run_ui()\n",
        "\n",
        "# Automatically finalize if running in 'test' mode\n",
        "if data_mode.value == 'test':\n",
        "    finalize(None)  # Simulate button click\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB9SPSWID986"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below (it should turn into <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/stop1.png\" height=\"25px\">)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tgnSnOM9z8gP"
      },
      "outputs": [],
      "source": [
        "#@title ‚Ü≥ Show input\n",
        "\n",
        "if 'filename' not in globals() or not filename:\n",
        "    print(\"‚ö†Ô∏è No data. Please load input DV file above!\")\n",
        "else:\n",
        "    # Load the image data from the file\n",
        "    lr_images = open_image_file(filename).astype(np.float64)\n",
        "\n",
        "    # Show a \"loading\" message first\n",
        "\n",
        "\n",
        "    display(HTML(html_code_clock))\n",
        "\n",
        "\n",
        "    # Generate animation HTML for the first 50 frames\n",
        "    anim_html = animate_50_frames(lr_images)\n",
        "\n",
        "    # JavaScript snippet to *replace* the \"loading\" text with \"Only first 50 frames are displayed.\"\n",
        "    replace_loading_js = \"\"\"\n",
        "    <script>\n",
        "    setTimeout(function(){\n",
        "        var loadingDiv = document.getElementById(\"loading-msg\");\n",
        "        if (loadingDiv) {\n",
        "            loadingDiv.innerHTML = '<br /><b>Only the first 50 frames are displayed.</b>';\n",
        "        }\n",
        "    }, 0);\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "    # Display the animation and then replace the \"Loading...\" message\n",
        "    display(anim_html)\n",
        "    display(HTML(replace_loading_js))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrFiVMHUEJYt"
      },
      "source": [
        "‚ùó‚ùó‚ùó Press <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below whenever you change the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YSAYthKegxlO"
      },
      "outputs": [],
      "source": [
        "#@title ‚öôÔ∏è Setup Parameters\n",
        "\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device_type}\")\n",
        "\n",
        "# Check if 'filename' and 'parameters' exist in the current session\n",
        "if 'filename' not in globals() or not filename:\n",
        "    # If there's no filename, display a message and stop\n",
        "    print(\"‚ö†Ô∏è No data. Please load input DV file above!\")\n",
        "else:\n",
        "    # We have a filename, so let's use 'parameters' if it exists or default to {}\n",
        "    if 'parameters' not in globals():\n",
        "        parameters = {}\n",
        "        print(\"‚ö†Ô∏è 'parameters' not found. Using empty defaults.\")\n",
        "    else:\n",
        "        print(f\"Data file to be processed: {filename}\\n\\n\")\n",
        "\n",
        "    # Extract sub-dictionaries with fallback defaults\n",
        "    otf_params       = parameters.get(\"otf_parameters\", {})\n",
        "    recon_params     = parameters.get(\"reconstruction_parameters\", {})\n",
        "    input_params     = parameters.get(\"input_parameters\", {})\n",
        "    detector_params  = parameters.get(\"detector_parameters\", {})\n",
        "    linking_params   = parameters.get(\"linking_parameters\", {})\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # Update function for all widgets\n",
        "    # ------------------------------------------\n",
        "    def update_values(_=None):\n",
        "        global image_size, na, px_size, wavelength, otf_curvature\n",
        "        global wiener_parameter, apodization_cutoff, apodization_bend\n",
        "        global background_threshold, border_fade, deconvolution_iterations, fit_exclude, batch_size\n",
        "        global checkpoint_path\n",
        "        global max_linking_distance, birth_death_cost, cls_cost_multiplier, gamma\n",
        "\n",
        "        # OTF Parameters\n",
        "        image_size        = image_size_widget.value\n",
        "        na                = na_widget.value\n",
        "        px_size           = px_size_widget.value\n",
        "        wavelength        = wavelength_widget.value\n",
        "        otf_curvature     = otf_curvature_widget.value\n",
        "\n",
        "        # Reconstruction Parameters\n",
        "        wiener_parameter  = wiener_parameter_widget.value\n",
        "        apodization_cutoff= apodization_cutoff_widget.value\n",
        "        apodization_bend  = apodization_bend_widget.value\n",
        "\n",
        "        # Input Parameters (excluding filename)\n",
        "        background_threshold    = background_threshold_widget.value\n",
        "        border_fade             = border_fade_widget.value\n",
        "        deconvolution_iterations= deconvolution_iterations_widget.value\n",
        "        fit_exclude             = fit_exclude_widget.value\n",
        "        batch_size              = batch_size_widget.value\n",
        "\n",
        "        # Detector Parameters\n",
        "        checkpoint_path         = checkpoint_path_widget.value\n",
        "\n",
        "        # Linking Parameters\n",
        "        max_linking_distance    = max_linking_distance_widget.value\n",
        "        birth_death_cost        = birth_death_cost_widget.value\n",
        "        cls_cost_multiplier     = cls_cost_multiplier_widget.value\n",
        "        gamma                   = gamma_widget.value\n",
        "\n",
        "    def attach_listeners(widget_list):\n",
        "        for w in widget_list:\n",
        "            w.observe(update_values, names=\"value\")\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # Define your widgets\n",
        "    # ------------------------------------------\n",
        "    label_width = '150px'\n",
        "    input_width = '300px'\n",
        "\n",
        "    # OTF widgets\n",
        "    image_size_widget = widgets.IntText(\n",
        "        value=otf_params.get(\"image_size\", 512),\n",
        "        description=\"Image Size:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    na_widget = widgets.FloatText(\n",
        "        value=otf_params.get(\"na\", 1.5),\n",
        "        description=\"NA:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    px_size_widget = widgets.FloatText(\n",
        "        value=otf_params.get(\"px_size\", 0.0791),\n",
        "        description=\"Pixel Size (¬µm):\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    wavelength_widget = widgets.IntText(\n",
        "        value=otf_params.get(\"wavelength\", 603),\n",
        "        description=\"Wavelength (nm):\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    otf_curvature_widget = widgets.FloatText(\n",
        "        value=otf_params.get(\"otf_curvature\", 0.3),\n",
        "        description=\"OTF Curvature:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "\n",
        "    otf_ui = VBox([\n",
        "        image_size_widget, na_widget, px_size_widget, wavelength_widget, otf_curvature_widget\n",
        "    ])\n",
        "    attach_listeners([image_size_widget, na_widget, px_size_widget, wavelength_widget, otf_curvature_widget])\n",
        "\n",
        "    # Reconstruction widgets\n",
        "    wiener_parameter_widget = widgets.FloatText(\n",
        "        value=recon_params.get(\"wiener_parameter\", 0.05),\n",
        "        description=\"Wiener Param:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    apodization_cutoff_widget = widgets.FloatText(\n",
        "        value=recon_params.get(\"apodization_cutoff\", 2.0),\n",
        "        description=\"Apod. Cutoff:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    apodization_bend_widget = widgets.FloatText(\n",
        "        value=recon_params.get(\"apodization_bend\", 0.9),\n",
        "        description=\"Apod. Bend:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "\n",
        "    reconstruction_ui = VBox([\n",
        "        wiener_parameter_widget, apodization_cutoff_widget, apodization_bend_widget\n",
        "    ])\n",
        "    attach_listeners([wiener_parameter_widget, apodization_cutoff_widget, apodization_bend_widget])\n",
        "\n",
        "    # Input widgets (excluding filename)\n",
        "    background_threshold_widget = widgets.IntText(\n",
        "        value=input_params.get(\"background_threshold\", 100),\n",
        "        description=\"Background Thr:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    border_fade_widget = widgets.IntText(\n",
        "        value=input_params.get(\"border_fade\", 15),\n",
        "        description=\"Border Fade:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    deconvolution_iterations_widget = widgets.IntText(\n",
        "        value=input_params.get(\"deconvolution_iterations\", 10),\n",
        "        description=\"Deconv. Iters:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    fit_exclude_widget = widgets.FloatText(\n",
        "        value=input_params.get(\"fit_exclude\", 0.75),\n",
        "        description=\"Fit Exclude:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    batch_size_widget = widgets.IntText(\n",
        "        value=input_params.get(\"batch_size\", 2),\n",
        "        description=\"Batch Size:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "\n",
        "    input_ui = VBox([\n",
        "        background_threshold_widget, border_fade_widget, deconvolution_iterations_widget,\n",
        "        fit_exclude_widget, batch_size_widget\n",
        "    ])\n",
        "    attach_listeners([\n",
        "        background_threshold_widget, border_fade_widget, deconvolution_iterations_widget,\n",
        "        fit_exclude_widget, batch_size_widget\n",
        "    ])\n",
        "\n",
        "    # Detector widget\n",
        "    checkpoint_path_widget = widgets.Text(\n",
        "        value=detector_params.get(\"checkpoint_path\", \"data/Interim/checkpoints/ccp-detector-sandy-wildflower-269.pt\"),\n",
        "        description=\"Checkpoint Path:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': '700px'}\n",
        "    )\n",
        "    detector_ui = VBox([checkpoint_path_widget])\n",
        "    attach_listeners([checkpoint_path_widget])\n",
        "\n",
        "    # Linking widgets\n",
        "    max_linking_distance_widget = widgets.FloatText(\n",
        "        value=linking_params.get(\"max_linking_distance\", 7.5),\n",
        "        description=\"Max Link Dist:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    birth_death_cost_widget = widgets.FloatText(\n",
        "        value=linking_params.get(\"birth_death_cost\", 5),\n",
        "        description=\"Birth/Death Cost:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    cls_cost_multiplier_widget = widgets.FloatText(\n",
        "        value=linking_params.get(\"cls_cost_multiplier\", 1),\n",
        "        description=\"Cls Multiplier:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "    gamma_widget = widgets.FloatText(\n",
        "        value=linking_params.get(\"gamma\", 10),\n",
        "        description=\"Gamma:\",\n",
        "        style={'description_width': label_width},\n",
        "        layout={'width': input_width}\n",
        "    )\n",
        "\n",
        "    linking_ui = VBox([\n",
        "        max_linking_distance_widget, birth_death_cost_widget, cls_cost_multiplier_widget, gamma_widget\n",
        "    ])\n",
        "    attach_listeners([\n",
        "        max_linking_distance_widget, birth_death_cost_widget,\n",
        "        cls_cost_multiplier_widget, gamma_widget\n",
        "    ])\n",
        "\n",
        "    # ------------------------------------------\n",
        "    # Display in Colab as tabbed widgets\n",
        "    # ------------------------------------------\n",
        "    def display_colab_widgets():\n",
        "        tab = colab_widgets.TabBar([\n",
        "            \"OTF Parameters\",\n",
        "            \"Reconstruction Parameters\",\n",
        "            \"Input Parameters\",\n",
        "            \"Detector Parameters\",\n",
        "            \"Linking Parameters\"\n",
        "        ], location=\"top\")\n",
        "\n",
        "        with tab.output_to(0):\n",
        "            display(otf_ui)\n",
        "        with tab.output_to(1):\n",
        "            display(reconstruction_ui)\n",
        "        with tab.output_to(2):\n",
        "            display(input_ui)\n",
        "        with tab.output_to(3):\n",
        "            display(detector_ui)\n",
        "        with tab.output_to(4):\n",
        "            display(linking_ui)\n",
        "\n",
        "    # Initialize and show\n",
        "    update_values()\n",
        "    display_colab_widgets()\n",
        "\n",
        "    print(\"\\n‚öôÔ∏è Setup loaded! You can adjust the parameters above.\")\n",
        "    print(\"üìù Any changes you make are saved instantly.\")\n",
        "    print(\"üîÅ Re-running the cell will reset all parameters to default.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlDvKiSaXNos"
      },
      "source": [
        "## üß© Reconstruction\n",
        "\n",
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/rec_head.svg\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpMuEtl9EP7Z"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bm3g6ZHEKcEl"
      },
      "outputs": [],
      "source": [
        "#@title Run Reconstruction\n",
        "\n",
        "display(HTML(html_code_reconstruction))\n",
        "time.sleep(0.1)\n",
        "\n",
        "otf = OTF(na, wavelength, px_size, image_size, otf_curvature)\n",
        "config = dict(na=na, wavelength=wavelength, px_size=px_size, wiener_parameter=wiener_parameter, apo_cutoff=apodization_cutoff, apo_bend=apodization_bend)\n",
        "ap = AcquisitionParameters(na=na, wavelength=wavelength, px_size=px_size, image_size=image_size)\n",
        "rp = ReconstructionParameters(wiener_parameter=wiener_parameter, apodization_cutoff=apodization_cutoff, apodization_bend=apodization_bend)\n",
        "\n",
        "lr_images = open_image_file(filename).astype(np.float64)\n",
        "\n",
        "# Common preprocessing for all images in the movie\n",
        "lr_images = subtract_background(lr_images, background_threshold)\n",
        "fade_border(lr_images, border_fade)\n",
        "\n",
        "# Estimate parameters on the first frame (9 images)\n",
        "rl_images = deconvolve_richardson_lucy(lr_images[:9], deconvolution_iterations, otf())\n",
        "f_images = np.fft.fft2(rl_images)\n",
        "\n",
        "components = separate_components(f_images)\n",
        "\n",
        "# This step may be skipped if we already have approximate shifts from a previous reconstruction\n",
        "minimum_distance = compute_minimum_distance(fit_exclude, image_size, px_size, na, wavelength)\n",
        "approximate_shifts = [estimate_integer_shift(components[i * 3], components[i * 3 + 1], minimum_distance)\n",
        "                      for i in range(3)]\n",
        "\n",
        "shifts = [optimizer_shift_v2(approximate_shifts[i], components[i * 3], components[i * 3 + 1])\n",
        "          for i in range(3)]\n",
        "\n",
        "phase_offsets = [estimate_phase_offset(f_images[i * 3:(i + 1) * 3], shifts[i])\n",
        "                 for i in range(3)]\n",
        "\n",
        "# This step is generally not possible to do accurately so we just hardcode the values but the estimated values serve as a quality metric of the reconstruction\n",
        "estimated_modulations = [estimate_phase_modulation(components[i * 3:(i + 1) * 3], shifts[i], otf)\n",
        "                         for i in range(3)]\n",
        "\n",
        "modulations = [1.0 for _ in range(3)]\n",
        "\n",
        "# Single frame cpu reconstruction\n",
        "fft_result, spatial_result = run_reconstruction(np.fft.fft2(lr_images[:9]), otf, shifts, phase_offsets, modulations, config)\n",
        "\n",
        "# Whole movie gpu reconstruction\n",
        "device = torch.device(device_type)\n",
        "\n",
        "clear_output(wait=True)\n",
        "\n",
        "r = Reconstruction(otf, shifts, phase_offsets, modulations, ap, rp, device)\n",
        "result = r.reconstruct(lr_images, batch_size)\n",
        "\n",
        "print(\"‚úÖ Reconstruction finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOCIDECVESQG"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below (it should turn into <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/stop1.png\" height=\"25px\">)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "grgXxa4Ew3Hg"
      },
      "outputs": [],
      "source": [
        "#@title ‚Ü≥ Show Reconstruction\n",
        "\n",
        "display(HTML(html_code_clock))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(result[0], cmap='gray')\n",
        "\n",
        "def animate(i):\n",
        "    im.set_array(result[i])\n",
        "    return [im]\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=result.shape[0], interval=100, blit=True)\n",
        "plt.close(fig)  # Prevent static image display\n",
        "\n",
        "anim_html = HTML(ani.to_jshtml())\n",
        "\n",
        "display(anim_html)\n",
        "\n",
        "remove_loading_js = \"\"\"\n",
        "<script>\n",
        "    // Remove the loading message after the animation HTML is inserted\n",
        "    setTimeout(function(){\n",
        "        var loadingDiv = document.getElementById(\"loading-msg\");\n",
        "        if (loadingDiv) {\n",
        "            loadingDiv.remove();\n",
        "        }\n",
        "    }, 0);\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(remove_loading_js))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tspPHIooZOkh"
      },
      "source": [
        "## üîç Detection\n",
        "\n",
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/det_head2.svg\" height=\"190\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSRBegmjEZG7"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9N6E5ULvLGIe"
      },
      "outputs": [],
      "source": [
        "#@title Run Detection\n",
        "display(HTML(html_code_detection))\n",
        "time.sleep(0.1)\n",
        "model = UNet(depth=3, start_filters=16, up_mode='nearest')\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device(device_type),weights_only=False)\n",
        "model.load_state_dict(checkpoint)\n",
        "model.eval()\n",
        "model.to(device);\n",
        "clear_output(wait=True)\n",
        "detections = generate_ccp_detections(model, device, result)\n",
        "print(\"‚úÖ Detection finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjRUGr63EZ_Z"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below (it should turn into <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/stop1.png\" height=\"25px\">)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "c7HeE5377xCN"
      },
      "outputs": [],
      "source": [
        "#@title ‚Ü≥ Show Detection Positions\n",
        "\n",
        "display(HTML(html_code_clock))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(result[0], cmap='gray')\n",
        "d0 = detections[detections.frame == 0]\n",
        "scat = ax.scatter(d0.x, d0.y, s=5, marker='+', c='red')\n",
        "\n",
        "def animate(i):\n",
        "    im.set_array(result[i])\n",
        "    di = detections[detections.frame == i]\n",
        "    if len(di) > 0:\n",
        "        scat.set_offsets(list(zip(di.x.values, di.y.values)))\n",
        "    else:\n",
        "        scat.set_offsets([])\n",
        "    return [im, scat]\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=result.shape[0], interval=100, blit=True)\n",
        "plt.close(fig)\n",
        "anim_html = HTML(ani.to_jshtml())\n",
        "display(anim_html)\n",
        "\n",
        "remove_loading_js = \"\"\"\n",
        "<script>\n",
        "    setTimeout(function(){\n",
        "        var loadingDiv = document.getElementById(\"loading-msg\");\n",
        "        if (loadingDiv) {\n",
        "            loadingDiv.remove();\n",
        "        }\n",
        "    }, 0);\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(remove_loading_js))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17VLL2S9ZWbl"
      },
      "source": [
        "## üîó Linking\n",
        "\n",
        "<img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/lin_head.png\" height=\"230\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkBXJX7jEcsU"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "RqCD0Uh5ZXwx"
      },
      "outputs": [],
      "source": [
        "#@title Run Linking\n",
        "\n",
        "def distance_function(a: pd.DataFrame, b: pd.DataFrame):\n",
        "    a_xy = np.array(a[['x', 'y']])\n",
        "    b_xy = np.array(b[['x', 'y']])\n",
        "    euclidian_dist = spatial.distance.cdist(a_xy, b_xy, metric='euclidean')\n",
        "\n",
        "    a_cls = np.array(a['cls'])\n",
        "    b_cls = np.array(b['cls'])\n",
        "    cls_dist = np.square(a_cls[:, None] - b_cls[None, :])\n",
        "\n",
        "    return euclidian_dist + cls_cost_multiplier * cls_dist\n",
        "\n",
        "def birth_death_cost_function(row: pd.Series):\n",
        "    return birth_death_cost + row['cls']\n",
        "\n",
        "display(HTML(html_code_linking))\n",
        "time.sleep(0.1)\n",
        "\n",
        "linking_graph = LinkingGraph(detections, distance_function, max_linking_distance, birth_death_cost_function)\n",
        "clear_output(wait=True)\n",
        "print(f'{linking_graph.solver.NumConstraints()} constraints, {linking_graph.solver.NumVariables()} variables')\n",
        "display(HTML(html_code_linking2))\n",
        "time.sleep(0.1)\n",
        "status = linking_graph.solve()\n",
        "print_solver_status(status, linking_graph.solver)\n",
        "\n",
        "tracklets = linking_graph.get_result()\n",
        "\n",
        "untangling_graph = UntanglingGraph(tracklets, gamma)\n",
        "clear_output(wait=True)\n",
        "print(f'{untangling_graph.solver.NumConstraints()} constraints, {untangling_graph.solver.NumVariables()} variables')\n",
        "display(HTML(html_code_linking2))\n",
        "time.sleep(0.1)\n",
        "status = untangling_graph.solve()\n",
        "print_solver_status(status, untangling_graph.solver)\n",
        "\n",
        "trajectories = untangling_graph.get_result(detections)\n",
        "\n",
        "# Filtering to remove very short tracks\n",
        "filtered_trajectories = trajectories.groupby('particle').filter(lambda t: t.frame.count() >= 6)\n",
        "clear_output(wait=True)\n",
        "\n",
        "print(\"‚úÖ Linking finished!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKV2uexzFOHl"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below (it should turn into <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/stop1.png\" height=\"25px\">)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "874BGbQoZuh6"
      },
      "outputs": [],
      "source": [
        "#@title ‚Ü≥ Show Linking\n",
        "\n",
        "display(HTML(html_code_clock))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(result[0], cmap='gray')\n",
        "\n",
        "# Configure tail length (how many past frames to show)\n",
        "tail_length = 10\n",
        "\n",
        "# Unique particles\n",
        "particles = filtered_trajectories['particle'].unique()\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, len(particles)))\n",
        "particle_color_map = dict(zip(particles, colors))\n",
        "\n",
        "# Initialize line artists for each particle\n",
        "line_artists = {pid: ax.plot([], [], color=particle_color_map[pid], lw=1)[0] for pid in particles}\n",
        "dot = ax.scatter([], [], s=5, marker='o', c='red')\n",
        "\n",
        "def animate(i):\n",
        "    im.set_array(result[i])\n",
        "\n",
        "    current = filtered_trajectories[\n",
        "        (filtered_trajectories['frame'] >= i - tail_length) &\n",
        "        (filtered_trajectories['frame'] <= i)\n",
        "    ]\n",
        "\n",
        "    # Update dot for current positions\n",
        "    now = current[current['frame'] == i]\n",
        "    dot.set_offsets(np.c_[now.x.values, now.y.values])\n",
        "\n",
        "    # Update each trajectory's line\n",
        "    for pid in particles:\n",
        "        trail = current[current['particle'] == pid].sort_values('frame')\n",
        "        if len(trail) >= 2:\n",
        "            line = line_artists[pid]\n",
        "            line.set_data(trail.x.values, trail.y.values)\n",
        "            line.set_alpha(1.0)  # current full line\n",
        "        else:\n",
        "            line_artists[pid].set_data([], [])\n",
        "            line_artists[pid].set_alpha(0.0)\n",
        "\n",
        "    return [im, dot] + list(line_artists.values())\n",
        "\n",
        "ani = animation.FuncAnimation(fig, animate, frames=result.shape[0], interval=100, blit=True)\n",
        "plt.close(fig)\n",
        "display(HTML(ani.to_jshtml()))\n",
        "\n",
        "# Remove loading text\n",
        "remove_loading_js = \"\"\"\n",
        "<script>\n",
        "    setTimeout(function(){\n",
        "        var loadingDiv = document.getElementById(\"loading-msg\");\n",
        "        if (loadingDiv) {\n",
        "            loadingDiv.remove();\n",
        "        }\n",
        "    }, 0);\n",
        "</script>\n",
        "\"\"\"\n",
        "display(HTML(remove_loading_js))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owTIuJG0Zjrl"
      },
      "source": [
        "## üìà Analysis\n",
        "\n",
        "\n",
        "\n",
        "> *‚ÄúAll this effort is only worthwhile if it leads to new biological discoveries. Discoveries that could not have been made with any other tool.‚Äù*\n",
        "Lothar, Royal Oak, circa July 2024\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imkgXCxnEeWF"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ddfH3wGY2qCa"
      },
      "outputs": [],
      "source": [
        "#@title Productivity  ‚ö†Ô∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "yeXUSJhvZhty"
      },
      "outputs": [],
      "source": [
        "#@title Relative frequency vs Lifetime\n",
        "\n",
        "# Fixed frame rate\n",
        "frame_rate = 3\n",
        "\n",
        "n_frames = len(result)\n",
        "mask = open_image_file(mask_filename).astype(np.float64)\n",
        "\n",
        "def update_plot(frame_rate):\n",
        "    lifetime_frames = (\n",
        "        filtered_trajectories.groupby('particle')\n",
        "        .filter(lambda t: (\n",
        "            (t.cls > 0.7).any() and\n",
        "            (0 < t.frame).all() and\n",
        "            (t.frame < n_frames - 1).all() and\n",
        "            (t.x > 15).all() and\n",
        "            (t.x < 1024 - 15).all() and\n",
        "            (t.y > 15).all() and\n",
        "            (t.y < 1024 - 15).all() and\n",
        "            mask[t.y.astype(int), t.x.astype(int)].all()\n",
        "        ))\n",
        "        .groupby('particle').frame.agg(lambda f: f.max() - f.min() + 1).values\n",
        "    )\n",
        "\n",
        "    lifetimes = lifetime_frames * frame_rate\n",
        "    lifetime_weights = (n_frames - 2) / (n_frames - 1 - lifetime_frames)\n",
        "\n",
        "    seconds_per_bin = 6\n",
        "    bin_edges = np.arange(10, 201, seconds_per_bin)\n",
        "\n",
        "    hist, _ = np.histogram(lifetimes, weights=lifetime_weights, bins=bin_edges, density=True)\n",
        "\n",
        "    # Plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot((bin_edges[1:] + bin_edges[:-1]) / 2, hist)\n",
        "    plt.xlabel('Lifetime [s]')\n",
        "    plt.ylabel('Relative frequency')\n",
        "    plt.xticks(np.arange(0, 201, 30))\n",
        "    plt.xticks(bin_edges, minor=True)\n",
        "    plt.tick_params(axis='x', which='minor', direction='in')\n",
        "    plt.show()\n",
        "\n",
        "# Run the plotting function once\n",
        "update_plot(frame_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExportHeading"
      },
      "source": [
        "## üì§ Export Results\n",
        "\n",
        "You can save important outputs (and inputs) to your Google Drive or computer. Select which outputs to include, then click **Prepare ZIP.** You can change the randomly generated name of the ZIP file. After that, you can either download the ZIP file or save it to your Google Drive. You can load the files back here later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKHthWzYFRbZ"
      },
      "source": [
        "Continue by pressing <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XclfpCYTvQIj"
      },
      "outputs": [],
      "source": [
        "#@title üì¶ Create Results ZIP\n",
        "\n",
        "\n",
        "adjectives = [\n",
        "    'silent', 'purple', 'ancient', 'rapid', 'curious', 'brave', 'happy', 'sleepy',\n",
        "    'bright', 'dark', 'fuzzy', 'eager', 'gentle', 'wild', 'quiet', 'fiery'\n",
        "]\n",
        "\n",
        "nouns = [\n",
        "    'otter', 'moon', 'mountain', 'river', 'cloud', 'panther', 'eagle', 'forest',\n",
        "    'breeze', 'ember', 'wave', 'meadow', 'shadow', 'falcon', 'comet', 'storm'\n",
        "]\n",
        "\n",
        "def generate_random_name():\n",
        "    adj = random.choice(adjectives)\n",
        "    noun = random.choice(nouns)\n",
        "    number = random.randint(100, 999)\n",
        "    return f\"{adj}_{noun}_{number}\"\n",
        "\n",
        "readme_text = \"\"\"SHAPE Export Package\n",
        "====================\n",
        "\n",
        "This ZIP file contains the exported results from your SHAPE analysis session.\n",
        "\n",
        "Contents may include:\n",
        "- parameters.json ............. Reconstruction and detection parameters\n",
        "- input.dv .................... The input DV file used in the analysis\n",
        "- mask_file.tif ............... The mask file used in the analysis\n",
        "- reconstruction.tif ......... Time-lapse TIF image of the reconstructed sample\n",
        "- detections.csv ............. Detected object positions (per frame)\n",
        "- trajectories.csv ........... Tracked particle trajectories across time\n",
        "- napari_show_detections.py .. Python script to view detections in napari\n",
        "- napari_show_trajectories.py. Python script to view trajectories in napari\n",
        "\n",
        "------------------------------------------------------------\n",
        "üìä Viewing the Results in Napari (Python-based viewer)\n",
        "------------------------------------------------------------\n",
        "\n",
        "1. Make sure you have napari and required libraries installed:\n",
        "\n",
        "   pip install napari[all] pandas scikit-image\n",
        "\n",
        "2. To view **detections**, run the following in terminal or Python:\n",
        "\n",
        "   python napari_show_detections.py\n",
        "\n",
        "   ‚Üí This will show the reconstructed image and overlay detections per time frame.\n",
        "\n",
        "3. To view **trajectories**, run:\n",
        "\n",
        "   python napari_show_trajectories.py\n",
        "\n",
        "   ‚Üí This will show tracked particles with trail lines over time.\n",
        "\n",
        "Make sure the corresponding reconstruction.tif and result .csv files\n",
        "are in the same directory as the Python scripts when running them.\n",
        "\n",
        "------------------------------------------------------------\n",
        "üí¨ Notes\n",
        "------------------------------------------------------------\n",
        "- Napari works best in a desktop environment.\n",
        "- These scripts use matplotlib, pandas, and skimage.\n",
        "- If you move the files elsewhere, keep related files together.\n",
        "\n",
        "Have fun exploring your data!\n",
        "\"\"\"\n",
        "\n",
        "base      = os.path.splitext(os.path.basename(filename))[0]\n",
        "# 1Ô∏è‚É£ Build the file‚Äêselection UI\n",
        "\n",
        "default_zip_name = f\"{generate_random_name()}.zip\"\n",
        "zipname_field = widgets.Text(value=default_zip_name, description='ZIP Name:', layout={'width': '700px'})\n",
        "input_cb    = widgets.Checkbox(value=True, description=\"Input Data (DV)\")\n",
        "mask_cb     = widgets.Checkbox(value=True, description=\"Mask File (TIFF)\")\n",
        "param_cb    = widgets.Checkbox(value=True, description=\"Parameters (JSON)\")\n",
        "recon_cb    = widgets.Checkbox(value=True, description=\"Reconstruction (TIFF)\")\n",
        "detect_cb   = widgets.Checkbox(value=True, description=\"Detections (CSV)\")\n",
        "tracks_cb   = widgets.Checkbox(value=True, description=\"Trajectories (CSV)\")\n",
        "\n",
        "prepare_btn = widgets.Button(description=\"üì¶ Prepare ZIP\", button_style='primary')\n",
        "output1     = widgets.Output()\n",
        "\n",
        "ui1 = widgets.VBox([\n",
        "    zipname_field,\n",
        "    input_cb,\n",
        "    mask_cb,\n",
        "    param_cb,\n",
        "    recon_cb,\n",
        "    detect_cb,\n",
        "    tracks_cb,\n",
        "    prepare_btn,\n",
        "    output1\n",
        "])\n",
        "display(ui1)\n",
        "\n",
        "# This will hold the name of the ZIP once created\n",
        "zip_name = None\n",
        "\n",
        "# 2Ô∏è‚É£ Preparation callback\n",
        "def on_prepare(_):\n",
        "    global zip_name\n",
        "    prepare_btn.disabled = True\n",
        "    with output1:\n",
        "        output1.clear_output()\n",
        "        label    = HTML(html_code_wait+'<b>üì¶ Creating ZIP‚Ä¶</b>')\n",
        "        display(label)\n",
        "        # Gather files\n",
        "        files_to_zip = []\n",
        "        if input_cb.value:\n",
        "            try: shutil.copy(filename, 'input.dv'); files_to_zip.append('input.dv')\n",
        "            except: pass\n",
        "        if mask_cb.value:\n",
        "            try: shutil.copy(mask_filename, 'mask_file.tif'); files_to_zip.append('mask_file.tif')\n",
        "            except: pass\n",
        "        if param_cb.value:\n",
        "            with open(\"parameters.json\",\"w\") as jf:\n",
        "                json.dump(parameters, jf, indent=4)\n",
        "            files_to_zip.append(\"parameters.json\")\n",
        "        if recon_cb.value and 'result' in globals():\n",
        "            import tifffile\n",
        "            tifffile.imwrite(\"reconstruction.tif\", np.array(result, dtype=np.float32))\n",
        "            files_to_zip.append(\"reconstruction.tif\")\n",
        "        if detect_cb.value and 'detections' in globals():\n",
        "            df = detections if isinstance(detections, pd.DataFrame) else pd.DataFrame(detections)\n",
        "            if 'cls' in df.columns:\n",
        "                df = df.rename(columns={'cls':'shape_index'})\n",
        "            df.to_csv(\"detections.csv\", index=False)\n",
        "            files_to_zip.append(\"detections.csv\")\n",
        "        if tracks_cb.value:\n",
        "            key = 'filtered_trajectories' if 'filtered_trajectories' in globals() else \\\n",
        "                  'trajectories'          if 'trajectories'          in globals() else None\n",
        "            if key:\n",
        "                df = globals()[key]\n",
        "                if 'cls' in df.columns:\n",
        "                    df = df.rename(columns={'cls': 'shape_index'})\n",
        "                df.to_csv(\"trajectories.csv\", index=False)\n",
        "                files_to_zip.append(\"trajectories.csv\")\n",
        "        for script in ['napari_show_detections.py','napari_show_trajectories.py']:\n",
        "            src = os.path.join(\"scripts\", script)\n",
        "            if os.path.exists(src):\n",
        "                shutil.copy(src, script)\n",
        "                files_to_zip.append(script)\n",
        "        # always include README\n",
        "        with open(\"README.txt\",\"w\") as f:\n",
        "            f.write(readme_text)\n",
        "        files_to_zip.append(\"README.txt\")\n",
        "\n",
        "        if not files_to_zip:\n",
        "            print(\"‚ö†Ô∏è No files selected to zip.\")\n",
        "            prepare_btn.disabled = False\n",
        "            return\n",
        "\n",
        "        # derive zip name\n",
        "        zip_name  = zipname_field.value.strip()\n",
        "\n",
        "        # show progress bar\n",
        "        from ipywidgets import IntProgress, HTML as WHTML, VBox\n",
        "        progress = IntProgress(min=0, max=len(files_to_zip), description='Zipping:')\n",
        "        display(VBox([progress]))\n",
        "\n",
        "        # write the archive\n",
        "        with zipfile.ZipFile(zip_name, \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
        "            for i, fname in enumerate(files_to_zip, start=1):\n",
        "                zf.write(fname)\n",
        "                progress.value = i\n",
        "\n",
        "        # 3Ô∏è‚É£ Clear logs & show only success\n",
        "        output1.clear_output()\n",
        "        # Hide checkboxes and button\n",
        "        zipname_field.layout.display = 'none'\n",
        "        input_cb.layout.display = 'none'\n",
        "        mask_cb.layout.display = 'none'\n",
        "        param_cb.layout.display = 'none'\n",
        "        recon_cb.layout.display = 'none'\n",
        "        detect_cb.layout.display = 'none'\n",
        "        tracks_cb.layout.display = 'none'\n",
        "        prepare_btn.layout.display = 'none'\n",
        "        display(widgets.HTML(f'<b>‚úÖ {zip_name} is ready!</b>'))\n",
        "\n",
        "\n",
        "prepare_btn.on_click(on_prepare)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKBRUS_fO6tw"
      },
      "source": [
        "‚ùó Click the <img src=\"https://shape.utia.cas.cz/files/endocytosis/colab_images/play.png\" height=\"20px\"> button below ‚Äî and click it again each time you change the destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DgipixZgLmhn"
      },
      "outputs": [],
      "source": [
        "#@title ‚¨áÔ∏è Download or Save to Drive\n",
        "\n",
        "import os, shutil\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "from ipyfilechooser import FileChooser\n",
        "\n",
        "# Colab helpers\n",
        "from google.colab import files as colab_files, drive\n",
        "from ipywidgets import IntProgress, HTML as WHTML, VBox\n",
        "\n",
        "# 1Ô∏è‚É£ UI widgets\n",
        "dest_radio  = widgets.RadioButtons(\n",
        "    options=[('Download locally','local'),\n",
        "             ('Save to Drive','drive')],\n",
        "    value='local',\n",
        "    description='Destination:'\n",
        ")\n",
        "\n",
        "drive_chooser = FileChooser('.', title='Pick a Drive folder', show_hidden=False)\n",
        "drive_chooser.show_only_dirs = True\n",
        "drive_chooser.hide_file     = True\n",
        "drive_chooser.layout.display = 'none'\n",
        "\n",
        "execute_btn = widgets.Button(description=\"‚ñ∂Ô∏è Execute\", button_style='primary')\n",
        "output2     = widgets.Output()\n",
        "\n",
        "ui2 = widgets.VBox([\n",
        "    dest_radio,\n",
        "    drive_chooser,\n",
        "    execute_btn,\n",
        "    output2\n",
        "])\n",
        "display(ui2)\n",
        "\n",
        "# 2Ô∏è‚É£ Show/hide chooser & mount on-demand\n",
        "def on_dest_change2(change):\n",
        "    if change['new']=='drive':\n",
        "        if not os.path.isdir('/content/drive/MyDrive'):\n",
        "            drive.mount('/content/drive')\n",
        "        drive_chooser.reset('/content/drive/MyDrive')\n",
        "        drive_chooser.layout.display = 'block'\n",
        "    else:\n",
        "        drive_chooser.layout.display = 'none'\n",
        "\n",
        "dest_radio.observe(on_dest_change2, names='value')\n",
        "\n",
        "# 3Ô∏è‚É£ Execution callback with single download + Drive‚Äêcopy progress\n",
        "download_triggered = False\n",
        "\n",
        "def on_execute(_):\n",
        "    global download_triggered\n",
        "    execute_btn.disabled = True  # prevent re-clicks\n",
        "    dest_radio.layout.display = 'none'\n",
        "    execute_btn.layout.display = 'none'\n",
        "    drive_chooser.layout.display = 'none'\n",
        "\n",
        "    with output2:\n",
        "        output2.clear_output()\n",
        "\n",
        "        if 'zip_name' not in globals() or not os.path.exists(zip_name):\n",
        "            print(\"‚ö†Ô∏è ZIP not found‚Äîplease run the Prepare cell first.\")\n",
        "            return\n",
        "\n",
        "        if dest_radio.value == 'local':\n",
        "            if not download_triggered:\n",
        "                colab_files.download(zip_name)\n",
        "                download_triggered = True\n",
        "            else:\n",
        "                print(\"‚úÖ Download already triggered.\")\n",
        "        else:\n",
        "            # Save to Drive with a progress bar\n",
        "            target = drive_chooser.selected_path\n",
        "            if not target or not os.path.isdir(target):\n",
        "                print(\"‚ö†Ô∏è Please pick a valid Drive folder above.\")\n",
        "                return\n",
        "\n",
        "            dst = os.path.join(target, zip_name)\n",
        "            if os.path.exists(dst):\n",
        "                display(widgets.HTML(f'‚úÖ Already saved at:<br><code>{dst}</code>'))\n",
        "                return\n",
        "\n",
        "            # chunked copy\n",
        "            total_size = os.path.getsize(zip_name)\n",
        "            progress   = IntProgress(min=0, max=total_size, description='Saving:')\n",
        "            label      = WHTML('<b>‚è≥ Saving to Drive‚Ä¶</b>')\n",
        "            display(VBox([label, progress]))\n",
        "\n",
        "            with open(zip_name, 'rb') as src, open(dst, 'wb') as dest:\n",
        "                chunk_size = 1_024*1_024  # 1 MB\n",
        "                written = 0\n",
        "                while True:\n",
        "                    chunk = src.read(chunk_size)\n",
        "                    if not chunk:\n",
        "                        break\n",
        "                    dest.write(chunk)\n",
        "                    written += len(chunk)\n",
        "                    progress.value = written\n",
        "\n",
        "            progress.close()\n",
        "            label.value = '<b>‚úÖ Saved to Drive!</b><br /><i>(It may take a minute for the file to appear in Drive.)</i>'\n",
        "\n",
        "execute_btn.on_click(on_execute)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}